2022-05-06 15:38:24 [scrapy.utils.log] INFO: Scrapy 2.5.1 started (bot: genericscrapy)
2022-05-06 15:38:24 [scrapy.utils.log] INFO: Versions: lxml 4.7.1.0, libxml2 2.9.12, cssselect 1.1.0, parsel 1.6.0, w3lib 1.22.0, Twisted 22.1.0, Python 3.8.5 (default, Sep  3 2020, 21:29:08) [MSC v.1916 64 bit (AMD64)], pyOpenSSL 22.0.0 (OpenSSL 1.1.1m  14 Dec 2021), cryptography 36.0.1, Platform Windows-10-10.0.18362-SP0
2022-05-06 15:38:24 [scrapy.utils.log] DEBUG: Using reactor: twisted.internet.selectreactor.SelectReactor
2022-05-06 15:38:24 [scrapy.crawler] INFO: Overridden settings:
{'BOT_NAME': 'genericscrapy',
 'DUPEFILTER_CLASS': 'scrapy_splash.SplashAwareDupeFilter',
 'HTTPCACHE_STORAGE': 'scrapy_splash.SplashAwareFSCacheStorage',
 'LOG_FILE': 'logs\\genericscrapy\\url-extractor\\2bdc3d9bcd4a11ecbd7be524b7200b1b.log',
 'NEWSPIDER_MODULE': 'genericscrapy.spiders',
 'SPIDER_MODULES': ['genericscrapy.spiders'],
 'USER_AGENT': 'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 '
               '(KHTML, like Gecko) Chrome/99.0.4844.51 Safari/537.36'}
2022-05-06 15:38:24 [scrapy.extensions.telnet] INFO: Telnet Password: c4796deef7b14435
2022-05-06 15:38:24 [scrapy.middleware] INFO: Enabled extensions:
['scrapy.extensions.corestats.CoreStats',
 'scrapy.extensions.telnet.TelnetConsole',
 'scrapy.extensions.logstats.LogStats']
2022-05-06 15:38:24 [url-extractor] INFO: [LE] Source: https://www.amazon.com/b?node=16225016011&pf_rd_r=N5TD9AJ5M2MFZYTD40G8&pf_rd_p=e5b0c85f-569c-4c90-a58f-0c0a260e45a0&pd_rd_r=c1e8591e-f091-4da5-8604-4635be6844be&pd_rd_w=bM1cA&pd_rd_wg=jgaTh&ref_=pd_gw_unk Depth: 0 Kwargs: {'_job': '2bdc3d9bcd4a11ecbd7be524b7200b1b'}
2022-05-06 15:38:24 [scrapy.middleware] INFO: Enabled downloader middlewares:
['scrapy.downloadermiddlewares.httpauth.HttpAuthMiddleware',
 'scrapy.downloadermiddlewares.downloadtimeout.DownloadTimeoutMiddleware',
 'scrapy.downloadermiddlewares.defaultheaders.DefaultHeadersMiddleware',
 'scrapy.downloadermiddlewares.useragent.UserAgentMiddleware',
 'scrapy.downloadermiddlewares.retry.RetryMiddleware',
 'scrapy.downloadermiddlewares.redirect.MetaRefreshMiddleware',
 'scrapy.downloadermiddlewares.redirect.RedirectMiddleware',
 'scrapy.downloadermiddlewares.cookies.CookiesMiddleware',
 'scrapy_splash.SplashCookiesMiddleware',
 'scrapy_splash.SplashMiddleware',
 'scrapy.downloadermiddlewares.httpproxy.HttpProxyMiddleware',
 'scrapy.downloadermiddlewares.httpcompression.HttpCompressionMiddleware',
 'scrapy.downloadermiddlewares.stats.DownloaderStats']
2022-05-06 15:38:24 [scrapy.middleware] INFO: Enabled spider middlewares:
['scrapy.spidermiddlewares.httperror.HttpErrorMiddleware',
 'scrapy_splash.SplashDeduplicateArgsMiddleware',
 'scrapy.spidermiddlewares.offsite.OffsiteMiddleware',
 'scrapy.spidermiddlewares.referer.RefererMiddleware',
 'scrapy.spidermiddlewares.urllength.UrlLengthMiddleware',
 'scrapy.spidermiddlewares.depth.DepthMiddleware']
2022-05-06 15:38:25 [kafka.producer.kafka] DEBUG: Starting the Kafka producer
2022-05-06 15:38:25 [kafka.metrics.metrics] DEBUG: Added sensor with name connections-closed
2022-05-06 15:38:25 [kafka.metrics.metrics] DEBUG: Added sensor with name connections-created
2022-05-06 15:38:25 [kafka.metrics.metrics] DEBUG: Added sensor with name select-time
2022-05-06 15:38:25 [kafka.metrics.metrics] DEBUG: Added sensor with name io-time
2022-05-06 15:38:25 [kafka.client] DEBUG: Initiating connection to node bootstrap-0 at localhost:9092
2022-05-06 15:38:25 [kafka.metrics.metrics] DEBUG: Added sensor with name bytes-sent-received
2022-05-06 15:38:25 [kafka.metrics.metrics] DEBUG: Added sensor with name bytes-sent
2022-05-06 15:38:25 [kafka.metrics.metrics] DEBUG: Added sensor with name bytes-received
2022-05-06 15:38:25 [kafka.metrics.metrics] DEBUG: Added sensor with name request-latency
2022-05-06 15:38:25 [kafka.metrics.metrics] DEBUG: Added sensor with name node-bootstrap-0.bytes-sent
2022-05-06 15:38:25 [kafka.metrics.metrics] DEBUG: Added sensor with name node-bootstrap-0.bytes-received
2022-05-06 15:38:25 [kafka.metrics.metrics] DEBUG: Added sensor with name node-bootstrap-0.latency
2022-05-06 15:38:25 [kafka.conn] DEBUG: <BrokerConnection node_id=bootstrap-0 host=localhost:9092 <disconnected> [unspecified None]>: creating new socket
2022-05-06 15:38:25 [kafka.conn] DEBUG: <BrokerConnection node_id=bootstrap-0 host=localhost:9092 <disconnected> [IPv6 ('::1', 9092, 0, 0)]>: setting socket option (6, 1, 1)
2022-05-06 15:38:25 [kafka.conn] INFO: <BrokerConnection node_id=bootstrap-0 host=localhost:9092 <connecting> [IPv6 ('::1', 9092, 0, 0)]>: connecting to localhost:9092 [('::1', 9092, 0, 0) IPv6]
2022-05-06 15:38:25 [kafka.conn] INFO: Probing node bootstrap-0 broker version
2022-05-06 15:38:27 [twisted] CRITICAL: Unhandled error in Deferred:
2022-05-06 15:38:27 [twisted] CRITICAL: 
Traceback (most recent call last):
  File "c:\users\kalil\scrapy\genericscrapy\venv\lib\site-packages\twisted\internet\defer.py", line 1660, in _inlineCallbacks
    result = current_context.run(gen.send, result)
  File "c:\users\kalil\scrapy\genericscrapy\venv\lib\site-packages\scrapy\crawler.py", line 87, in crawl
    self.engine = self._create_engine()
  File "c:\users\kalil\scrapy\genericscrapy\venv\lib\site-packages\scrapy\crawler.py", line 101, in _create_engine
    return ExecutionEngine(self, lambda _: self.stop())
  File "c:\users\kalil\scrapy\genericscrapy\venv\lib\site-packages\scrapy\core\engine.py", line 70, in __init__
    self.scraper = Scraper(crawler)
  File "c:\users\kalil\scrapy\genericscrapy\venv\lib\site-packages\scrapy\core\scraper.py", line 71, in __init__
    self.itemproc = itemproc_cls.from_crawler(crawler)
  File "c:\users\kalil\scrapy\genericscrapy\venv\lib\site-packages\scrapy\middleware.py", line 53, in from_crawler
    return cls.from_settings(crawler.settings, crawler)
  File "c:\users\kalil\scrapy\genericscrapy\venv\lib\site-packages\scrapy\middleware.py", line 35, in from_settings
    mw = create_instance(mwcls, settings, crawler)
  File "c:\users\kalil\scrapy\genericscrapy\venv\lib\site-packages\scrapy\utils\misc.py", line 169, in create_instance
    instance = objcls.from_settings(settings, *args, **kwargs)
  File "c:\users\kalil\appdata\local\temp\genericscrapy-1650278973-z8b39xtj.egg\genericscrapy\pipelines.py", line 49, in from_settings
  File "c:\users\kalil\scrapy\genericscrapy\venv\lib\site-packages\kafka\producer\kafka.py", line 381, in __init__
    client = KafkaClient(metrics=self._metrics, metric_group_prefix='producer',
  File "c:\users\kalil\scrapy\genericscrapy\venv\lib\site-packages\kafka\client_async.py", line 244, in __init__
    self.config['api_version'] = self.check_version(timeout=check_timeout)
  File "c:\users\kalil\scrapy\genericscrapy\venv\lib\site-packages\kafka\client_async.py", line 927, in check_version
    raise Errors.NoBrokersAvailable()
kafka.errors.NoBrokersAvailable: NoBrokersAvailable
