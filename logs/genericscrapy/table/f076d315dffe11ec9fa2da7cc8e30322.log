2022-05-30 10:57:45 [scrapy.utils.log] INFO: Scrapy 2.5.1 started (bot: genericscrapy)
2022-05-30 10:57:45 [scrapy.utils.log] INFO: Versions: lxml 4.7.1.0, libxml2 2.9.12, cssselect 1.1.0, parsel 1.6.0, w3lib 1.22.0, Twisted 21.7.0, Python 3.8.5 (default, Sep  3 2020, 21:29:08) [MSC v.1916 64 bit (AMD64)], pyOpenSSL 22.0.0 (OpenSSL 1.1.1m  14 Dec 2021), cryptography 36.0.1, Platform Windows-10-10.0.18362-SP0
2022-05-30 10:57:45 [scrapy.utils.log] DEBUG: Using reactor: twisted.internet.asyncioreactor.AsyncioSelectorReactor
2022-05-30 10:57:45 [scrapy.utils.log] DEBUG: Using asyncio event loop: asyncio.windows_events._WindowsSelectorEventLoop
2022-05-30 10:57:45 [scrapy.crawler] INFO: Overridden settings:
{'BOT_NAME': 'genericscrapy',
 'CLOSESPIDER_PAGECOUNT': 1000,
 'DOWNLOAD_DELAY': 10,
 'DUPEFILTER_CLASS': 'scrapy_splash.SplashAwareDupeFilter',
 'HTTPCACHE_STORAGE': 'scrapy_splash.SplashAwareFSCacheStorage',
 'LOG_FILE': 'logs\\genericscrapy\\table\\f076d315dffe11ec9fa2da7cc8e30322.log',
 'NEWSPIDER_MODULE': 'genericscrapy.spiders',
 'SPIDER_MODULES': ['genericscrapy.spiders'],
 'USER_AGENT': 'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 '
               '(KHTML, like Gecko) Chrome/99.0.4844.51 Safari/537.36'}
2022-05-30 10:57:45 [scrapy.extensions.telnet] INFO: Telnet Password: 97ca89620626ecec
2022-05-30 10:57:45 [scrapy.middleware] INFO: Enabled extensions:
['scrapy.extensions.corestats.CoreStats',
 'scrapy.extensions.telnet.TelnetConsole',
 'scrapy.extensions.closespider.CloseSpider',
 'scrapy.extensions.logstats.LogStats']
2022-05-30 10:57:45 [scrapy.middleware] INFO: Enabled downloader middlewares:
['scrapy.downloadermiddlewares.httpauth.HttpAuthMiddleware',
 'scrapy.downloadermiddlewares.downloadtimeout.DownloadTimeoutMiddleware',
 'scrapy.downloadermiddlewares.defaultheaders.DefaultHeadersMiddleware',
 'scrapy.downloadermiddlewares.useragent.UserAgentMiddleware',
 'scrapy.downloadermiddlewares.retry.RetryMiddleware',
 'scrapy.downloadermiddlewares.redirect.MetaRefreshMiddleware',
 'scrapy.downloadermiddlewares.redirect.RedirectMiddleware',
 'scrapy.downloadermiddlewares.cookies.CookiesMiddleware',
 'scrapy_splash.SplashCookiesMiddleware',
 'scrapy_splash.SplashMiddleware',
 'scrapy.downloadermiddlewares.httpproxy.HttpProxyMiddleware',
 'scrapy.downloadermiddlewares.httpcompression.HttpCompressionMiddleware',
 'scrapy.downloadermiddlewares.stats.DownloaderStats']
2022-05-30 10:57:45 [scrapy.middleware] INFO: Enabled spider middlewares:
['scrapy.spidermiddlewares.httperror.HttpErrorMiddleware',
 'scrapy_splash.SplashDeduplicateArgsMiddleware',
 'scrapy.spidermiddlewares.offsite.OffsiteMiddleware',
 'scrapy.spidermiddlewares.referer.RefererMiddleware',
 'scrapy.spidermiddlewares.urllength.UrlLengthMiddleware',
 'scrapy.spidermiddlewares.depth.DepthMiddleware']
2022-05-30 10:57:45 [scrapy.middleware] INFO: Enabled item pipelines:
['genericscrapy.pipelines.TableScraperPipeline']
2022-05-30 10:57:45 [scrapy.core.engine] INFO: Spider opened
2022-05-30 10:57:45 [py.warnings] WARNING: c:\users\kalil\scrapy\venv\lib\site-packages\cryptography\x509\base.py:538: CryptographyDeprecationWarning: Parsed a negative serial number, which is disallowed by RFC 5280.
  return rust_x509.load_der_x509_certificate(data)

2022-05-30 10:57:46 [scrapy.extensions.logstats] INFO: Crawled 0 pages (at 0 pages/min), scraped 0 items (at 0 items/min)
2022-05-30 10:57:46 [scrapy.extensions.telnet] INFO: Telnet console listening on 127.0.0.1:6023
2022-05-30 10:57:46 [pymongo.ocsp_support] DEBUG: Peer did not staple an OCSP response
2022-05-30 10:57:46 [pymongo.ocsp_support] DEBUG: Requesting OCSP data
2022-05-30 10:57:46 [pymongo.ocsp_support] DEBUG: Trying http://r3.o.lencr.org
2022-05-30 10:57:46 [urllib3.connectionpool] DEBUG: Starting new HTTP connection (1): r3.o.lencr.org:80
2022-05-30 10:57:46 [pymongo.ocsp_support] DEBUG: Peer did not staple an OCSP response
2022-05-30 10:57:46 [pymongo.ocsp_support] DEBUG: Requesting OCSP data
2022-05-30 10:57:46 [pymongo.ocsp_support] DEBUG: Trying http://r3.o.lencr.org
2022-05-30 10:57:46 [urllib3.connectionpool] DEBUG: Starting new HTTP connection (1): r3.o.lencr.org:80
2022-05-30 10:57:46 [urllib3.connectionpool] DEBUG: http://r3.o.lencr.org:80 "POST / HTTP/1.1" 200 503
2022-05-30 10:57:46 [urllib3.connectionpool] DEBUG: http://r3.o.lencr.org:80 "POST / HTTP/1.1" 200 503
2022-05-30 10:57:46 [pymongo.ocsp_support] DEBUG: OCSP response status: <OCSPResponseStatus.SUCCESSFUL: 0>
2022-05-30 10:57:46 [pymongo.ocsp_support] DEBUG: OCSP response status: <OCSPResponseStatus.SUCCESSFUL: 0>
2022-05-30 10:57:46 [pymongo.ocsp_support] DEBUG: Verifying response
2022-05-30 10:57:46 [pymongo.ocsp_support] DEBUG: Verifying response
2022-05-30 10:57:46 [pymongo.ocsp_support] DEBUG: Peer did not staple an OCSP response
2022-05-30 10:57:46 [pymongo.ocsp_support] DEBUG: Responder is issuer
2022-05-30 10:57:46 [pymongo.ocsp_support] DEBUG: Responder is issuer
2022-05-30 10:57:46 [pymongo.ocsp_support] DEBUG: Requesting OCSP data
2022-05-30 10:57:46 [pymongo.ocsp_support] DEBUG: Caching OCSP response.
2022-05-30 10:57:46 [pymongo.ocsp_support] DEBUG: Trying http://r3.o.lencr.org
2022-05-30 10:57:46 [pymongo.ocsp_support] DEBUG: Caching OCSP response.
2022-05-30 10:57:46 [pymongo.ocsp_support] DEBUG: OCSP cert status: <OCSPCertStatus.GOOD: 0>
2022-05-30 10:57:46 [pymongo.ocsp_support] DEBUG: Using cached OCSP response.
2022-05-30 10:57:46 [pymongo.ocsp_support] DEBUG: OCSP cert status: <OCSPCertStatus.GOOD: 0>
2022-05-30 10:57:46 [pymongo.ocsp_support] DEBUG: OCSP cert status: <OCSPCertStatus.GOOD: 0>
2022-05-30 10:57:46 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://www.appeloffres.com/> (referer: None)
2022-05-30 10:57:46 [pymongo.ocsp_support] DEBUG: Peer did not staple an OCSP response
2022-05-30 10:57:46 [pymongo.ocsp_support] DEBUG: Requesting OCSP data
2022-05-30 10:57:46 [pymongo.ocsp_support] DEBUG: Trying http://r3.o.lencr.org
2022-05-30 10:57:46 [pymongo.ocsp_support] DEBUG: Using cached OCSP response.
2022-05-30 10:57:46 [pymongo.ocsp_support] DEBUG: OCSP cert status: <OCSPCertStatus.GOOD: 0>
2022-05-30 10:57:46 [pymongo.ocsp_support] DEBUG: Peer did not staple an OCSP response
2022-05-30 10:57:46 [pymongo.ocsp_support] DEBUG: Requesting OCSP data
2022-05-30 10:57:46 [pymongo.ocsp_support] DEBUG: Trying http://r3.o.lencr.org
2022-05-30 10:57:46 [pymongo.ocsp_support] DEBUG: Using cached OCSP response.
2022-05-30 10:57:46 [pymongo.ocsp_support] DEBUG: OCSP cert status: <OCSPCertStatus.GOOD: 0>
2022-05-30 10:57:46 [pymongo.ocsp_support] DEBUG: Peer did not staple an OCSP response
2022-05-30 10:57:46 [pymongo.ocsp_support] DEBUG: Requesting OCSP data
2022-05-30 10:57:46 [pymongo.ocsp_support] DEBUG: Trying http://r3.o.lencr.org
2022-05-30 10:57:46 [pymongo.ocsp_support] DEBUG: Using cached OCSP response.
2022-05-30 10:57:46 [pymongo.ocsp_support] DEBUG: OCSP cert status: <OCSPCertStatus.GOOD: 0>
2022-05-30 10:57:47 [scrapy.core.scraper] ERROR: Spider error processing <GET https://www.appeloffres.com/> (referer: None)
Traceback (most recent call last):
  File "c:\users\kalil\scrapy\venv\lib\site-packages\scrapy\utils\defer.py", line 120, in iter_errback
    yield next(it)
  File "c:\users\kalil\scrapy\venv\lib\site-packages\scrapy\utils\python.py", line 353, in __next__
    return next(self.data)
  File "c:\users\kalil\scrapy\venv\lib\site-packages\scrapy\utils\python.py", line 353, in __next__
    return next(self.data)
  File "c:\users\kalil\scrapy\venv\lib\site-packages\scrapy\core\spidermw.py", line 56, in _evaluate_iterable
    for r in iterable:
  File "c:\users\kalil\scrapy\venv\lib\site-packages\scrapy_splash\middleware.py", line 162, in process_spider_output
    for el in result:
  File "c:\users\kalil\scrapy\venv\lib\site-packages\scrapy\core\spidermw.py", line 56, in _evaluate_iterable
    for r in iterable:
  File "c:\users\kalil\scrapy\venv\lib\site-packages\scrapy\spidermiddlewares\offsite.py", line 29, in process_spider_output
    for x in result:
  File "c:\users\kalil\scrapy\venv\lib\site-packages\scrapy\core\spidermw.py", line 56, in _evaluate_iterable
    for r in iterable:
  File "c:\users\kalil\scrapy\venv\lib\site-packages\scrapy\spidermiddlewares\referer.py", line 342, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "c:\users\kalil\scrapy\venv\lib\site-packages\scrapy\core\spidermw.py", line 56, in _evaluate_iterable
    for r in iterable:
  File "c:\users\kalil\scrapy\venv\lib\site-packages\scrapy\spidermiddlewares\urllength.py", line 40, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "c:\users\kalil\scrapy\venv\lib\site-packages\scrapy\core\spidermw.py", line 56, in _evaluate_iterable
    for r in iterable:
  File "c:\users\kalil\scrapy\venv\lib\site-packages\scrapy\spidermiddlewares\depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "c:\users\kalil\scrapy\venv\lib\site-packages\scrapy\core\spidermw.py", line 56, in _evaluate_iterable
    for r in iterable:
  File "c:\users\kalil\appdata\local\temp\genericscrapy-1653901977-u_l_39w7.egg\genericscrapy\spiders\TableScraper.py", line 22, in parse
    df = pd.read_html(response.request.url,match="Description sommaire de l'appel d'offres")
  File "c:\users\kalil\scrapy\venv\lib\site-packages\pandas\util\_decorators.py", line 311, in wrapper
    return func(*args, **kwargs)
  File "c:\users\kalil\scrapy\venv\lib\site-packages\pandas\io\html.py", line 1113, in read_html
    return _parse(
  File "c:\users\kalil\scrapy\venv\lib\site-packages\pandas\io\html.py", line 915, in _parse
    parser = _parser_dispatch(flav)
  File "c:\users\kalil\scrapy\venv\lib\site-packages\pandas\io\html.py", line 864, in _parser_dispatch
    raise ImportError("html5lib not found, please install it")
ImportError: html5lib not found, please install it
2022-05-30 10:58:05 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://www.appeloffres.com/resultat?p=tunisie> (referer: None)
2022-05-30 10:58:12 [pymongo.ocsp_support] DEBUG: Peer did not staple an OCSP response
2022-05-30 10:58:12 [pymongo.ocsp_support] DEBUG: Requesting OCSP data
2022-05-30 10:58:12 [pymongo.ocsp_support] DEBUG: Trying http://r3.o.lencr.org
2022-05-30 10:58:12 [pymongo.ocsp_support] DEBUG: Using cached OCSP response.
2022-05-30 10:58:12 [pymongo.ocsp_support] DEBUG: OCSP cert status: <OCSPCertStatus.GOOD: 0>
2022-05-30 10:58:14 [root] DEBUG: Post added to MongoDB
2022-05-30 10:58:14 [scrapy.core.scraper] DEBUG: Scraped from <200 https://www.appeloffres.com/resultat?p=tunisie>
{'Nom': 'GE', 'Date': '28/05/2022', 'Type': 'Nat./TUN', 'Référence': '83410008', "Description sommaire de l'appel d'offres": "Mise en place d'un dispositif de conduite de changement", 'Catégorie': 'Fournitures Industrielles', 'Echéance': '03/06/2022 00:00:00'}
2022-05-30 10:58:15 [root] DEBUG: Post added to MongoDB
2022-05-30 10:58:15 [scrapy.core.scraper] DEBUG: Scraped from <200 https://www.appeloffres.com/resultat?p=tunisie>
{'Nom': 'CE', 'Date': '28/05/2022', 'Type': 'Nat./TUN', 'Référence': 'Consultation 01/2022', "Description sommaire de l'appel d'offres": 'Etude de la chaine de valeur tapis et tissage fait mains', 'Catégorie': 'Études et consulting', 'Echéance': '20/06/2022 00:00:00'}
2022-05-30 10:58:16 [root] DEBUG: Post added to MongoDB
2022-05-30 10:58:16 [scrapy.core.scraper] DEBUG: Scraped from <200 https://www.appeloffres.com/resultat?p=tunisie>
{'Nom': 'GE', 'Date': '28/05/2022', 'Type': 'Nat./TUN', 'Référence': '83409024', "Description sommaire de l'appel d'offres": "Mission d'appui à la communication pour le projet CQE", 'Catégorie': 'Services', 'Echéance': '03/06/2022 00:00:00'}
2022-05-30 10:58:17 [root] DEBUG: Post added to MongoDB
2022-05-30 10:58:17 [scrapy.core.scraper] DEBUG: Scraped from <200 https://www.appeloffres.com/resultat?p=tunisie>
{'Nom': 'UN', 'Date': '28/05/2022', 'Type': 'Nat./TUN', 'Référence': 'Avis de consultation I04/2022', "Description sommaire de l'appel d'offres": "Acquisition d'une solution Anti-Plagiat", 'Catégorie': 'Informatique matériels et logiciels', 'Echéance': '06/06/2022 10:00:00'}
2022-05-30 10:58:19 [root] DEBUG: Post added to MongoDB
2022-05-30 10:58:19 [scrapy.core.scraper] DEBUG: Scraped from <200 https://www.appeloffres.com/resultat?p=tunisie>
{'Nom': 'SO', 'Date': '28/05/2022', 'Type': 'Nat./TUN', 'Référence': '49879/22', "Description sommaire de l'appel d'offres": 'Acquisition de matériel pour le serpentin du four 02F103/F104', 'Catégorie': 'Fournitures Industrielles', 'Echéance': '13/06/2022 10:00:00'}
2022-05-30 10:58:20 [root] DEBUG: Post added to MongoDB
2022-05-30 10:58:20 [scrapy.core.scraper] DEBUG: Scraped from <200 https://www.appeloffres.com/resultat?p=tunisie>
{'Nom': 'OF', 'Date': '28/05/2022', 'Type': 'Nat./TUN', 'Référence': '07-2022/DG/ONT', "Description sommaire de l'appel d'offres": "Désignation d'un avocat ou cabinet d'avocats professionnels représentant l'office", 'Catégorie': 'Services', 'Echéance': '17/06/2022 12:00:00'}
2022-05-30 10:58:21 [root] DEBUG: Post added to MongoDB
2022-05-30 10:58:21 [scrapy.core.scraper] DEBUG: Scraped from <200 https://www.appeloffres.com/resultat?p=tunisie>
{'Nom': 'AG', 'Date': '28/05/2022', 'Type': 'Nat./TUN', 'Référence': 'Consultation 22/2022', "Description sommaire de l'appel d'offres": 'Acquisition du matériel lumière', 'Catégorie': 'Fournitures Industrielles', 'Echéance': '08/06/0202 10:00:00'}
2022-05-30 10:58:23 [root] DEBUG: Post added to MongoDB
2022-05-30 10:58:23 [scrapy.core.scraper] DEBUG: Scraped from <200 https://www.appeloffres.com/resultat?p=tunisie>
{'Nom': 'GE', 'Date': '28/05/2022', 'Type': 'Nat./TUN', 'Référence': '91162866', "Description sommaire de l'appel d'offres": 'Acquisition des équipements informatiques', 'Catégorie': 'Informatique matériels et logiciels', 'Echéance': '03/06/2022 00:00:00'}
2022-05-30 10:58:24 [root] DEBUG: Post added to MongoDB
2022-05-30 10:58:24 [scrapy.core.scraper] DEBUG: Scraped from <200 https://www.appeloffres.com/resultat?p=tunisie>
{'Nom': "L'", 'Date': '28/05/2022', 'Type': 'Nat./TUN', 'Référence': '16/2022 Consultation', "Description sommaire de l'appel d'offres": 'La réalisation des travaux de chargement , transport, déchargement et enfouissement des boues', 'Catégorie': 'BTP TP', 'Echéance': '06/06/2022 17:00:00'}
2022-05-30 10:58:25 [root] DEBUG: Post added to MongoDB
2022-05-30 10:58:25 [scrapy.core.scraper] DEBUG: Scraped from <200 https://www.appeloffres.com/resultat?p=tunisie>
{'Nom': "L'", 'Date': '28/05/2022', 'Type': 'Nat./TUN', 'Référence': 'Avis de consultation 21/DRGT/2022', "Description sommaire de l'appel d'offres": "Travaux de curage des réseaux d'assainissement en eaux usées dans le gouvernorat de Ben Arous", 'Catégorie': 'BTP TP', 'Echéance': '06/06/2022 16:00:00'}
2022-05-30 10:58:26 [root] DEBUG: Post added to MongoDB
2022-05-30 10:58:26 [scrapy.core.scraper] DEBUG: Scraped from <200 https://www.appeloffres.com/resultat?p=tunisie>
{'Nom': 'MU', 'Date': '28/05/2022', 'Type': 'Nat./TUN', 'Référence': '04/2022', "Description sommaire de l'appel d'offres": 'Acquisition de matériels de propreté et des voiries: un élévateur et un tracteur agricole', 'Catégorie': 'Voitures camions et engins', 'Echéance': '30/06/2022 10:00:00'}
2022-05-30 10:58:26 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://www.appeloffres.com/resultat?p=algerie> (referer: None)
2022-05-30 10:58:27 [root] DEBUG: Post added to MongoDB
2022-05-30 10:58:27 [scrapy.core.scraper] DEBUG: Scraped from <200 https://www.appeloffres.com/resultat?p=tunisie>
{'Nom': 'ST', 'Date': '28/05/2022', 'Type': 'Nat./TUN', 'Référence': '2022 D 3934', "Description sommaire de l'appel d'offres": "Additif de l'appel d'offres relatif aux travaux de pose réseau gaz (PE 4 BAR): Alimentation en gaz", 'Catégorie': 'BTP TP', 'Echéance': '08/06/2022 09:00:00'}
2022-05-30 10:58:28 [root] DEBUG: Post added to MongoDB
2022-05-30 10:58:28 [scrapy.core.scraper] DEBUG: Scraped from <200 https://www.appeloffres.com/resultat?p=tunisie>
{'Nom': 'PH', 'Date': '28/05/2022', 'Type': 'Nat./TUN', 'Référence': 'Consultation 21/2022', "Description sommaire de l'appel d'offres": 'Acquisition et montage de pneus', 'Catégorie': 'Fournitures Industrielles', 'Echéance': '07/06/2022 10:00:00'}
2022-05-30 10:58:31 [scrapy.core.scraper] DEBUG: Scraped from <200 https://www.appeloffres.com/resultat?p=algerie>
None
2022-05-30 10:58:32 [root] DEBUG: Post added to MongoDB
2022-05-30 10:58:32 [scrapy.core.scraper] DEBUG: Scraped from <200 https://www.appeloffres.com/resultat?p=tunisie>
{'Nom': 'HO', 'Date': '28/05/2022', 'Type': 'Rep./TUN', 'Référence': '04/2022', "Description sommaire de l'appel d'offres": "Report de l'appel d'offre relatif au choix d’un bureau d’études, d’un ingénieur ou d’un groupement", 'Catégorie': 'Études et consulting', 'Echéance': '08/06/2022 10:00:00'}
2022-05-30 10:58:33 [scrapy.core.scraper] DEBUG: Scraped from <200 https://www.appeloffres.com/resultat?p=algerie>
None
2022-05-30 10:58:34 [root] DEBUG: Post added to MongoDB
2022-05-30 10:58:34 [scrapy.core.scraper] DEBUG: Scraped from <200 https://www.appeloffres.com/resultat?p=tunisie>
{'Nom': 'ST', 'Date': '28/05/2022', 'Type': 'Nat./TUN', 'Référence': '2022 G 22 Consultation', "Description sommaire de l'appel d'offres": 'Contrôles réglémentaires en usine (En Turquie) des tubes de diamètres 12 pouces', 'Catégorie': 'Études et consulting', 'Echéance': '21/06/2022 09:00:00'}
2022-05-30 10:58:34 [scrapy.core.scraper] DEBUG: Scraped from <200 https://www.appeloffres.com/resultat?p=algerie>
None
2022-05-30 10:58:35 [scrapy.core.scraper] DEBUG: Scraped from <200 https://www.appeloffres.com/resultat?p=tunisie>
None
2022-05-30 10:58:36 [scrapy.core.scraper] DEBUG: Scraped from <200 https://www.appeloffres.com/resultat?p=algerie>
None
2022-05-30 10:58:37 [scrapy.core.scraper] DEBUG: Scraped from <200 https://www.appeloffres.com/resultat?p=tunisie>
None
2022-05-30 10:58:38 [scrapy.core.scraper] DEBUG: Scraped from <200 https://www.appeloffres.com/resultat?p=algerie>
None
2022-05-30 10:58:39 [scrapy.core.scraper] DEBUG: Scraped from <200 https://www.appeloffres.com/resultat?p=tunisie>
None
2022-05-30 10:58:40 [scrapy.core.scraper] DEBUG: Scraped from <200 https://www.appeloffres.com/resultat?p=algerie>
None
2022-05-30 10:58:41 [scrapy.core.scraper] DEBUG: Scraped from <200 https://www.appeloffres.com/resultat?p=tunisie>
None
2022-05-30 10:58:42 [scrapy.core.scraper] DEBUG: Scraped from <200 https://www.appeloffres.com/resultat?p=algerie>
None
2022-05-30 10:58:43 [scrapy.core.scraper] DEBUG: Scraped from <200 https://www.appeloffres.com/resultat?p=tunisie>
None
2022-05-30 10:58:44 [scrapy.core.scraper] DEBUG: Scraped from <200 https://www.appeloffres.com/resultat?p=algerie>
None
2022-05-30 10:58:45 [root] DEBUG: Post added to MongoDB
2022-05-30 10:58:45 [scrapy.core.scraper] DEBUG: Scraped from <200 https://www.appeloffres.com/resultat?p=tunisie>
{'Nom': 'IN', 'Date': '27/05/2022', 'Type': 'Nat./TUN', 'Référence': '06/2022', "Description sommaire de l'appel d'offres": 'Acquisition des climatiseurs', 'Catégorie': 'Fournitures Industrielles', 'Echéance': '16/06/2022 10:00:00'}
2022-05-30 10:58:46 [scrapy.core.scraper] DEBUG: Scraped from <200 https://www.appeloffres.com/resultat?p=algerie>
None
2022-05-30 10:58:47 [scrapy.core.scraper] DEBUG: Scraped from <200 https://www.appeloffres.com/resultat?p=tunisie>
None
2022-05-30 10:58:47 [scrapy.extensions.logstats] INFO: Crawled 3 pages (at 3 pages/min), scraped 31 items (at 31 items/min)
2022-05-30 10:58:49 [scrapy.core.scraper] DEBUG: Scraped from <200 https://www.appeloffres.com/resultat?p=algerie>
None
2022-05-30 10:58:49 [scrapy.core.scraper] DEBUG: Scraped from <200 https://www.appeloffres.com/resultat?p=tunisie>
None
2022-05-30 10:58:50 [scrapy.core.scraper] DEBUG: Scraped from <200 https://www.appeloffres.com/resultat?p=algerie>
None
2022-05-30 10:58:50 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://www.appeloffres.com/resultat?p=maroc> (referer: None)
2022-05-30 10:58:51 [scrapy.core.scraper] DEBUG: Scraped from <200 https://www.appeloffres.com/resultat?p=tunisie>
None
2022-05-30 10:58:53 [scrapy.core.scraper] DEBUG: Scraped from <200 https://www.appeloffres.com/resultat?p=algerie>
None
2022-05-30 10:58:54 [scrapy.core.scraper] DEBUG: Scraped from <200 https://www.appeloffres.com/resultat?p=tunisie>
None
2022-05-30 10:58:59 [scrapy.core.scraper] DEBUG: Scraped from <200 https://www.appeloffres.com/resultat?p=algerie>
None
2022-05-30 10:59:03 [scrapy.core.scraper] ERROR: Spider error processing <GET https://www.appeloffres.com/resultat?p=maroc> (referer: None)
Traceback (most recent call last):
  File "c:\users\kalil\scrapy\venv\lib\site-packages\scrapy\utils\defer.py", line 120, in iter_errback
    yield next(it)
  File "c:\users\kalil\scrapy\venv\lib\site-packages\scrapy\utils\python.py", line 353, in __next__
    return next(self.data)
  File "c:\users\kalil\scrapy\venv\lib\site-packages\scrapy\utils\python.py", line 353, in __next__
    return next(self.data)
  File "c:\users\kalil\scrapy\venv\lib\site-packages\scrapy\core\spidermw.py", line 56, in _evaluate_iterable
    for r in iterable:
  File "c:\users\kalil\scrapy\venv\lib\site-packages\scrapy_splash\middleware.py", line 162, in process_spider_output
    for el in result:
  File "c:\users\kalil\scrapy\venv\lib\site-packages\scrapy\core\spidermw.py", line 56, in _evaluate_iterable
    for r in iterable:
  File "c:\users\kalil\scrapy\venv\lib\site-packages\scrapy\spidermiddlewares\offsite.py", line 29, in process_spider_output
    for x in result:
  File "c:\users\kalil\scrapy\venv\lib\site-packages\scrapy\core\spidermw.py", line 56, in _evaluate_iterable
    for r in iterable:
  File "c:\users\kalil\scrapy\venv\lib\site-packages\scrapy\spidermiddlewares\referer.py", line 342, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "c:\users\kalil\scrapy\venv\lib\site-packages\scrapy\core\spidermw.py", line 56, in _evaluate_iterable
    for r in iterable:
  File "c:\users\kalil\scrapy\venv\lib\site-packages\scrapy\spidermiddlewares\urllength.py", line 40, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "c:\users\kalil\scrapy\venv\lib\site-packages\scrapy\core\spidermw.py", line 56, in _evaluate_iterable
    for r in iterable:
  File "c:\users\kalil\scrapy\venv\lib\site-packages\scrapy\spidermiddlewares\depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "c:\users\kalil\scrapy\venv\lib\site-packages\scrapy\core\spidermw.py", line 56, in _evaluate_iterable
    for r in iterable:
  File "c:\users\kalil\appdata\local\temp\genericscrapy-1653901977-u_l_39w7.egg\genericscrapy\spiders\TableScraper.py", line 31, in parse
    print(df[x])
  File "C:\Users\kalil\anaconda3\lib\encodings\cp1252.py", line 19, in encode
    return codecs.charmap_encode(input,self.errors,encoding_table)[0]
UnicodeEncodeError: 'charmap' codec can't encode characters in position 475-476: character maps to <undefined>
2022-05-30 10:59:05 [scrapy.core.scraper] DEBUG: Scraped from <200 https://www.appeloffres.com/resultat?p=tunisie>
None
2022-05-30 10:59:09 [scrapy.core.scraper] DEBUG: Scraped from <200 https://www.appeloffres.com/resultat?p=algerie>
None
2022-05-30 10:59:13 [scrapy.core.scraper] DEBUG: Scraped from <200 https://www.appeloffres.com/resultat?p=tunisie>
None
2022-05-30 10:59:19 [scrapy.core.scraper] DEBUG: Scraped from <200 https://www.appeloffres.com/resultat?p=algerie>
None
