2022-06-01 15:40:49 [scrapy.utils.log] INFO: Scrapy 2.5.1 started (bot: genericscrapy)
2022-06-01 15:40:49 [scrapy.utils.log] INFO: Versions: lxml 4.7.1.0, libxml2 2.9.12, cssselect 1.1.0, parsel 1.6.0, w3lib 1.22.0, Twisted 21.7.0, Python 3.8.5 (default, Sep  3 2020, 21:29:08) [MSC v.1916 64 bit (AMD64)], pyOpenSSL 22.0.0 (OpenSSL 1.1.1m  14 Dec 2021), cryptography 36.0.1, Platform Windows-10-10.0.18362-SP0
2022-06-01 15:40:49 [scrapy.utils.log] DEBUG: Using reactor: twisted.internet.asyncioreactor.AsyncioSelectorReactor
2022-06-01 15:40:49 [scrapy.utils.log] DEBUG: Using asyncio event loop: asyncio.windows_events._WindowsSelectorEventLoop
2022-06-01 15:40:49 [scrapy.crawler] INFO: Overridden settings:
{'BOT_NAME': 'genericscrapy',
 'CLOSESPIDER_PAGECOUNT': 1000,
 'DOWNLOAD_DELAY': 10,
 'DUPEFILTER_CLASS': 'scrapy_splash.SplashAwareDupeFilter',
 'HTTPCACHE_STORAGE': 'scrapy_splash.SplashAwareFSCacheStorage',
 'LOG_FILE': 'logs\\genericscrapy\\table\\d1c3e080e1b811ec8497d41e27300ada.log',
 'NEWSPIDER_MODULE': 'genericscrapy.spiders',
 'SPIDER_MODULES': ['genericscrapy.spiders'],
 'USER_AGENT': 'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 '
               '(KHTML, like Gecko) Chrome/99.0.4844.51 Safari/537.36'}
2022-06-01 15:40:49 [scrapy.extensions.telnet] INFO: Telnet Password: a8e34b0115376d9b
2022-06-01 15:40:49 [scrapy.middleware] INFO: Enabled extensions:
['scrapy.extensions.corestats.CoreStats',
 'scrapy.extensions.telnet.TelnetConsole',
 'scrapy.extensions.closespider.CloseSpider',
 'scrapy.extensions.logstats.LogStats']
2022-06-01 15:40:49 [twisted] CRITICAL: Unhandled error in Deferred:
2022-06-01 15:40:49 [twisted] CRITICAL: 
Traceback (most recent call last):
  File "c:\users\kalil\scrapy\venv\lib\site-packages\twisted\internet\defer.py", line 1661, in _inlineCallbacks
    result = current_context.run(gen.send, result)
  File "c:\users\kalil\scrapy\venv\lib\site-packages\scrapy\crawler.py", line 86, in crawl
    self.spider = self._create_spider(*args, **kwargs)
  File "c:\users\kalil\scrapy\venv\lib\site-packages\scrapy\crawler.py", line 98, in _create_spider
    return self.spidercls.from_crawler(self, *args, **kwargs)
  File "c:\users\kalil\scrapy\venv\lib\site-packages\scrapy\spiders\__init__.py", line 50, in from_crawler
    spider = cls(*args, **kwargs)
TypeError: __init__() missing 1 required positional argument: 'collection_name'
